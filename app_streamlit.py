import streamlit as st
from dotenv import load_dotenv
from langgraph.checkpoint.memory import MemorySaver
from workflow import GRAPH, GraphState

load_dotenv()

st.set_page_config(page_title="RAG Chatbot (LangGraph)", page_icon="ğŸ”")
st.title("ğŸ” LangChain/LangGraph ê¸°ë°˜ RAG ì±—ë´‡")

with st.sidebar:
    st.markdown("### ì„¤ì •")
    question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", value="í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê³¼ rerankingì´ ë­ì˜ˆìš”?")
    if st.button("ì§ˆë¬¸ ë³´ë‚´ê¸°", type="primary"):
        st.session_state["go"] = True

if st.session_state.get("go"):
    with st.spinner("ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘..."):
        state = GraphState(question=question)
        result = GRAPH.invoke(state.dict())
        st.success("ì™„ë£Œ!")
        st.markdown("#### ë‹µë³€")
        st.write(result.get("answer", ""))

        st.markdown("#### ë©”íƒ€ë°ì´í„°/ê²€ì¦ ì •ë³´")
        st.json(result.get("meta", {}))

        if result.get("contexts"):
            st.markdown("#### ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸")
            for i, c in enumerate(result["contexts"], 1):
                with st.expander(f"ì»¨í…ìŠ¤íŠ¸ {i}"):
                    st.write(c)
