import os
import streamlit as st
from typing import List
from dotenv import load_dotenv

# LangChain ê´€ë ¨
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# OpenAI (LangChain ì „ìš© ë˜í¼)
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# PDF ì²˜ë¦¬
from pypdf import PdfReader

# ê¸°ë³¸ ì„¤ì •
load_dotenv()

st.set_page_config(
    page_title="ë‚˜ë§Œì˜ RAG ì±—ë´‡ (ì¤‘ê°„ê³ ì‚¬)",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ---- ì‚¬ì´ë“œë°” ë””ìì¸ ----
st.sidebar.title("âš™ï¸ ì„¤ì •")
with st.sidebar.expander("ğŸ“Œ ì•ˆë‚´ (í•„ë…)", expanded=True):
    st.markdown(
        """
        **ê³¼ì œ ì²´í¬ë¦¬ìŠ¤íŠ¸**
        - [x] LangChain + Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ RAG êµ¬í˜„ (ì—…ë¡œë“œ íŒŒì¼ ê¸°ë°˜)
        - [x] Streamlit UI ë° ì»¤ìŠ¤í…€ ë””ìì¸
        - [x] Streamlit Cloud ë°°í¬ ê°€ëŠ¥ êµ¬ì¡°
        - [x] ë¦¬í¬íŠ¸ì™€ ì½”ë“œ ì œê³µ
        
        **í•„ìˆ˜ ì¤€ë¹„**
        1) OpenAI API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ `OPENAI_API_KEY`ë¡œ ë“±ë¡í•´ ì£¼ì„¸ìš”.
        2) ì¢Œì¸¡ ìƒë‹¨ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , ì„ë² ë”© êµ¬ì¶• í›„ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.
        """
    )

# ---- ê°„ë‹¨í•œ ìŠ¤íƒ€ì¼(Custom CSS) ----
st.markdown(
    """
    <style>
        .main .block-container {padding-top: 1.5rem; padding-bottom: 2rem;}
        .chat-bubble-user {background:#eef4ff; padding:14px 16px; border-radius:16px; margin:6px 0; }
        .chat-bubble-bot {background:#f6f6f6; padding:14px 16px; border-radius:16px; margin:6px 0; border-left:4px solid #5b9bd5;}
        .source-card {border:1px solid #e6e6e6; padding:10px; border-radius:12px; margin-top:8px;}
        .tiny {font-size: 12px; color:#666;}
        .pill {display:inline-block; padding:3px 8px; border-radius:999px; background:#edf2f7; margin-right:6px;}
    </style>
    """,
    unsafe_allow_html=True
)

# ---- ì„¸ì…˜ ìƒíƒœ ----
if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "docs" not in st.session_state:
    st.session_state.docs = []
if "history" not in st.session_state:
    st.session_state.history = []

# ---- í—¤ë” ----
st.title("ğŸ¤– ë‚˜ë§Œì˜ RAG ì±—ë´‡")
st.caption("LangChain + Streamlit | íŒŒì¼ ì—…ë¡œë“œ ê¸°ë°˜ ê²€ìƒ‰ ì¦ê°• ìƒì„± (RAG)")

# ---- íŒŒì¼ ì—…ë¡œë“œ ----
uploaded_files = st.file_uploader(
    "ğŸ“„ ì°¸ê³ í•  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF/TXT, ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
    type=["pdf", "txt"],
    accept_multiple_files=True
)

col1, col2, col3 = st.columns([1,1,1])
with col1:
    chunk_size = st.number_input("ì²­í¬ í¬ê¸°", min_value=200, max_value=3000, step=100, value=1000)
with col2:
    chunk_overlap = st.number_input("ì²­í¬ ì¤‘ì²©", min_value=0, max_value=800, step=50, value=150)
with col3:
    top_k = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ (k)", min_value=1, max_value=10, value=4)

build_clicked = st.button("ğŸ”¨ ì„ë² ë”©/ì¸ë±ìŠ¤ êµ¬ì¶•")

def read_pdf(file) -> str:
    pdf = PdfReader(file)
    texts = []
    for page in pdf.pages:
        texts.append(page.extract_text() or "")
    return "\n".join(texts)

def read_txt(file) -> str:
    return file.read().decode("utf-8", errors="ignore")

def load_documents(files) -> List[Document]:
    docs = []
    for f in files:
        name = getattr(f, "name", "uploaded")
        if name.lower().endswith(".pdf"):
            text = read_pdf(f)
        elif name.lower().endswith(".txt"):
            text = read_txt(f)
        else:
            continue
        metadata = {"source": name}
        docs.append(Document(page_content=text, metadata=metadata))
    return docs

def build_vectorstore(docs: List[Document], chunk_size:int, chunk_overlap:int):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=int(chunk_size), chunk_overlap=int(chunk_overlap), separators=["\n\n", "\n", " ", ""]
    )
    splits = text_splitter.split_documents(docs)
    embeddings = OpenAIEmbeddings()  # OPENAI_API_KEY í•„ìš”
    vs = FAISS.from_documents(splits, embedding=embeddings)
    return vs

if build_clicked:
    if not uploaded_files:
        st.warning("ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        with st.spinner("ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•˜ëŠ” ì¤‘..."):
            try:
                st.session_state.docs = load_documents(uploaded_files)
                st.session_state.vectorstore = build_vectorstore(st.session_state.docs, chunk_size, chunk_overlap)
                st.success("ì™„ë£Œ! ì´ì œ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”.")
            except Exception as e:
                st.error(f"ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘ ì˜¤ë¥˜: {e}")

# ---- ì§ˆë¬¸ UI ----
st.subheader("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")
question = st.text_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? (ì˜ˆ: ì´ ë¬¸ì„œì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?)")
ask = st.button("ì§ˆë¬¸ ë³´ë‚´ê¸°")

def build_chain(top_k:int):
    retriever = st.session_state.vectorstore.as_retriever(search_kwargs={"k": int(top_k)})
    template = """
ë‹¹ì‹ ì€ ì—…ë¡œë“œëœ ìë£Œë¥¼ ê·¼ê±°ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ëŠ” ì¡°êµì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ê·¼ê±°(ì¶œì²˜ íŒŒì¼ëª…)ë¥¼ ìš”ì•½ ëì— 'ê·¼ê±°:' ë’¤ì— ë‚˜ì—´í•˜ì„¸ìš”.
ì‚¬ìš©ì ì§ˆë¬¸: {question}
ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ í•œêµ­ì–´ ë‹µë³€:"""
    prompt = PromptTemplate.from_template(template)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
    qa = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt}
    )
    return qa

if ask:
    if st.session_state.vectorstore is None:
        st.warning("ë¨¼ì € íŒŒì¼ ì—…ë¡œë“œ í›„ 'ì„ë² ë”©/ì¸ë±ìŠ¤ êµ¬ì¶•'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    elif not question.strip():
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                qa = build_chain(top_k)
                result = qa({"query": question})
                answer = result["result"]

                # ê°„ë‹¨í•œ ì¶œì²˜ í‘œì‹œìš©
                sources = []
                try:
                    docs = st.session_state.vectorstore.similarity_search(question, k=int(top_k))
                    for d in docs:
                        sources.append(d.metadata.get("source", "unknown"))
                except Exception:
                    pass

                st.session_state.history.append(("user", question))
                st.session_state.history.append(("bot", answer, sources))

            except Exception as e:
                st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ---- ëŒ€í™” í‘œì‹œ ----
st.subheader("ğŸ§¾ ëŒ€í™” ê¸°ë¡")
for item in st.session_state.history:
    if item[0] == "user":
        st.markdown(f'<div class="chat-bubble-user"><b>ë‚˜</b><br>{item[1]}</div>', unsafe_allow_html=True)
    else:
        answer, srcs = item[1], item[2]
        st.markdown(f'<div class="chat-bubble-bot"><b>ë´‡</b><br>{answer}</div>', unsafe_allow_html=True)
        if srcs:
            with st.expander("ğŸ” ì°¸ê³ /ê·¼ê±° ë¬¸ì„œ"):
                for s in srcs:
                    st.markdown(f"- `{s}`")

# ---- í‘¸í„° ----
import time as _t
st.markdown(
    '<p class="tiny">Â© {year} ì¤‘ê°„ê³ ì‚¬ìš© RAG ë°ëª¨ | ë°°í¬ íŒ: ì¢Œì¸¡ ì•ˆë‚´ë¥¼ ì°¸ê³ í•˜ì—¬ Streamlit Cloudì— ì—…ë¡œë“œí•˜ì„¸ìš”.</p>'.format(year=_t.strftime("%Y")),
    unsafe_allow_html=True
)