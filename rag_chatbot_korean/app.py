import os
import streamlit as st
from dotenv import load_dotenv
from typing import List, Dict
from pypdf import PdfReader

from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate

load_dotenv()
st.set_page_config(page_title="ë‚˜ë§Œì˜ RAG ì±—ë´‡ (ì´ˆê°„ë‹¨ ì•ˆì •íŒ)", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– ë‚˜ë§Œì˜ RAG ì±—ë´‡ (ì´ˆê°„ë‹¨ ì•ˆì •íŒ)")
st.caption("íŒŒì¼ ì—…ë¡œë“œ â†’ ì²­í¬ ë¶„í•  â†’ í‚¤ì›Œë“œ ì ìˆ˜ë¡œ ìƒìœ„ ë¬¸ë§¥ ì„ íƒ â†’ LLM ë‹µë³€ (ê·¼ê±° í‘œì‹œ)")

# ì„¸ì…˜ ìƒíƒœ
if "splits" not in st.session_state:
    st.session_state.splits: List[Dict] = []
if "history" not in st.session_state:
    st.session_state.history = []

# ì‚¬ì´ë“œë°”
st.sidebar.header("âš™ï¸ ì„¤ì •")
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.sidebar.error("Secretsì— OPENAI_API_KEYë¥¼ ë“±ë¡í•˜ì„¸ìš”.")
else:
    st.sidebar.success("OPENAI_API_KEY ê°ì§€ë¨")

# ì—…ë¡œë“œ
uploaded = st.file_uploader("ğŸ“„ PDF/TXT ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["pdf", "txt"], accept_multiple_files=True)

col1, col2 = st.columns(2)
with col1:
    chunk_size = st.number_input("ì²­í¬ í¬ê¸°", 200, 3000, 1000, 100)
with col2:
    chunk_overlap = st.number_input("ì²­í¬ ì¤‘ì²©", 0, 800, 150, 50)

def read_pdf(file) -> str:
    pdf = PdfReader(file)
    texts = []
    for p in pdf.pages:
        texts.append(p.extract_text() or "")
    return "\n".join(texts)

def read_txt(file) -> str:
    return file.read().decode("utf-8", errors="ignore")

def split_text(text: str, size: int, overlap: int) -> List[str]:
    chunks = []
    i = 0
    while i < len(text):
        chunks.append(text[i:i+size])
        i += max(1, size - overlap)
    return chunks

if st.button("ğŸ”¨ ì¸ë±ìŠ¤ êµ¬ì¶•"):
    if not uploaded:
        st.warning("ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        splits = []
        for f in uploaded:
            name = getattr(f, "name", "uploaded")
            if name.lower().endswith(".pdf"):
                content = read_pdf(f)
            else:
                content = read_txt(f)
            for ch in split_text(content, int(chunk_size), int(chunk_overlap)):
                if ch.strip():
                    splits.append({"text": ch, "source": name})
        st.session_state.splits = splits
        st.success(f"ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ! ì²­í¬ ìˆ˜: {len(splits)}")

# ê°„ë‹¨ í‚¤ì›Œë“œ ì ìˆ˜ ê¸°ë°˜ ê²€ìƒ‰
def rank_by_keywords(query: str, splits: List[Dict], k: int = 4) -> List[Dict]:
    q_tokens = [t for t in query.lower().split() if t.strip()]
    scores = []
    for s in splits:
        text = s["text"].lower()
        score = sum(text.count(t) for t in q_tokens) + 1e-6  # ìµœì†Œê°’
        scores.append((score, s))
    scores.sort(key=lambda x: x[0], reverse=True)
    return [s for _, s in scores[:k]]

st.subheader("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")
q = st.text_input("ì˜ˆ: ì´ ë¬¸ì„œì˜ í•µì‹¬ ìš”ì•½ì€?")
top_k = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ (k)", 1, 10, 4)
ask = st.button("ì§ˆë¬¸ ë³´ë‚´ê¸°")

if ask:
    if not st.session_state.splits:
        st.warning("ë¨¼ì € ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.")
    elif not q.strip():
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        try:
            top_docs = rank_by_keywords(q, st.session_state.splits, int(top_k))
            context = "\n\n---\n\n".join([d["text"] for d in top_docs])
            sources = ", ".join(sorted({d["source"] for d in top_docs}))

            template = """
ë‹¹ì‹ ì€ ì—…ë¡œë“œëœ ìë£Œë¥¼ ê·¼ê±°ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
[ìë£Œ]
{context}

[ì§ˆë¬¸]
{question}

ê·œì¹™:
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€
- ë§ˆì§€ë§‰ ì¤„ì— 'ê·¼ê±°:' ë’¤ì— ì¶œì²˜ íŒŒì¼ëª… ë‚˜ì—´

ë‹µë³€:
"""
            prompt = PromptTemplate.from_template(template)
            llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
            resp = llm.invoke(prompt.format(context=context, question=q)).content
            # ê·¼ê±° ë³´ê°•
            if "ê·¼ê±°:" not in resp:
                resp += f"\n\nê·¼ê±°: {sources if sources else 'ì—…ë¡œë“œ ìë£Œ'}"

            st.session_state.history.append(("user", q))
            st.session_state.history.append(("bot", resp, list(sorted({d['source'] for d in top_docs}))))

        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

st.subheader("ğŸ§¾ ëŒ€í™” ê¸°ë¡")
for item in st.session_state.history:
    if item[0] == "user":
        st.markdown(f"**ë‚˜:** {item[1]}")
    else:
        ans, srcs = item[1], item[2]
        st.markdown(f"**ë´‡:** {ans}")
        if srcs:
            with st.expander("ğŸ” ì°¸ê³ /ê·¼ê±° ë¬¸ì„œ"):
                for s in srcs:
                    st.markdown(f"- `{s}`")
