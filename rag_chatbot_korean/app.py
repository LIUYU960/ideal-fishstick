import os
import time
from typing import List, Dict
from textwrap import dedent

import streamlit as st
from dotenv import load_dotenv
from pypdf import PdfReader

from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from openai import RateLimitError  # 429 í•œë„ ì´ˆê³¼ ì²˜ë¦¬ìš©

# ------------------------
# ê¸°ë³¸ ì„¤ì •
# ------------------------
load_dotenv()
st.set_page_config(page_title="ë‚˜ë§Œì˜ RAG ì±—ë´‡ (ì´ˆê°„ë‹¨ ì•ˆì •íŒ, í•œê¸€)", page_icon="ğŸ¤–", layout="wide")

# ---- ìŠ¤íƒ€ì¼ ----
st.markdown(
    """
    <style>
        .main .block-container {padding-top: 1.2rem; padding-bottom: 2rem;}
        .chat-bubble-user {background:#eef4ff; padding:14px 16px; border-radius:16px; margin:6px 0;}
        .chat-bubble-bot  {background:#f6f6f6; padding:14px 16px; border-radius:16px; margin:6px 0; border-left:4px solid #5b9bd5;}
        .tiny {font-size: 12px; color:#666;}
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ¤– ë‚˜ë§Œì˜ RAG ì±—ë´‡ (ì´ˆê°„ë‹¨ ì•ˆì •íŒ)")
st.caption("íŒŒì¼ ì—…ë¡œë“œ â†’ ì²­í¬ ë¶„í•  â†’ í‚¤ì›Œë“œ ì ìˆ˜ë¡œ ìƒìœ„ ë¬¸ë§¥ ì„ íƒ â†’ LLM ë‹µë³€ (ê·¼ê±° í‘œì‹œ)")

# ------------------------
# API Key (Secrets ìš°ì„ , ê·¸ ì™¸ ENV)
# ------------------------
api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
if api_key:
    os.environ["OPENAI_API_KEY"] = api_key  # í•˜ìœ„ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì½ë„ë¡
    st.sidebar.success("OPENAI_API_KEY ê°ì§€ë¨")
else:
    st.sidebar.error("Secretsì— OPENAI_API_KEYë¥¼ ë“±ë¡í•˜ì„¸ìš”.")

# ------------------------
# ì„¸ì…˜ ìƒíƒœ
# ------------------------
if "splits" not in st.session_state:
    st.session_state.splits: List[Dict] = []
if "history" not in st.session_state:
    st.session_state.history = []

# ------------------------
# ì—…ë¡œë“œ & íŒŒë¼ë¯¸í„°
# ------------------------
st.sidebar.header("âš™ï¸ ì„¤ì •")
uploaded_files = st.file_uploader("ğŸ“„ PDF/TXT ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["pdf", "txt"], accept_multiple_files=True)

col1, col2 = st.columns(2)
with col1:
    chunk_size = st.number_input("ì²­í¬ í¬ê¸°", min_value=200, max_value=3000, step=100, value=1000)
with col2:
    chunk_overlap = st.number_input("ì²­í¬ ì¤‘ì²©", min_value=0, max_value=800, step=50, value=150)

# ------------------------
# ìœ í‹¸ í•¨ìˆ˜
# ------------------------
def read_pdf(file) -> str:
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ PDFë¥¼ ì½ì–´ ë¬¸ìì—´ë¡œ ë³€í™˜ (ìŠ¤ìº” PDFëŠ” ë¹„ê¶Œì¥)."""
    pdf = PdfReader(file)
    texts = []
    for p in pdf.pages:
        texts.append(p.extract_text() or "")
    return "\n".join(texts)

def read_txt(file) -> str:
    """TXT íŒŒì¼ ì½ê¸° (UTF-8, ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ)."""
    return file.read().decode("utf-8", errors="ignore")

def split_text(text: str, size: int, overlap: int) -> List[str]:
    """ì•„ì£¼ ë‹¨ìˆœí•œ ê³ ì •ê¸¸ì´ ì²­í¬ ë¶„í• ê¸° (ì˜ì¡´ì„± ìµœì†Œí™”)."""
    chunks = []
    i = 0
    step = max(1, size - overlap)
    while i < len(text):
        chunks.append(text[i:i + size])
        i += step
    return chunks

def build_splits_from_uploads(files, size: int, overlap: int) -> List[Dict]:
    """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ë¡œ ì²­í¬ ë¦¬ìŠ¤íŠ¸(splits) ìƒì„±."""
    tmp = []
    for f in files:
        name = getattr(f, "name", "uploaded")
        if name.lower().endswith(".pdf"):
            content = read_pdf(f)
        elif name.lower().endswith(".txt"):
            content = read_txt(f)
        else:
            continue  # ì§€ì›í•˜ì§€ ì•ŠëŠ” í™•ì¥ì
        for ch in split_text(content, int(size), int(overlap)):
            if ch.strip():
                tmp.append({"text": ch, "source": name})
    return tmp

def rank_by_keywords(query: str, splits: List[Dict], k: int = 4) -> List[Dict]:
    """ì•„ì£¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ë¹ˆë„ ìŠ¤ì½”ì–´(ìˆœìˆ˜ íŒŒì´ì¬)."""
    q_tokens = [t for t in query.lower().split() if t.strip()]
    if not q_tokens:
        return splits[:k]
    scored = []
    for s in splits:
        text = s["text"].lower()
        score = sum(text.count(t) for t in q_tokens) + 1e-6
        scored.append((score, s))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [s for _, s in scored[:k]]

def ensure_index_from_uploads():
    """ì¸ë±ìŠ¤ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì—…ë¡œë“œ íŒŒì¼ë¡œ ìë™ êµ¬ì¶•."""
    if st.session_state.splits:
        return
    if not uploaded_files:
        return
    st.session_state.splits = build_splits_from_uploads(uploaded_files, chunk_size, chunk_overlap)

# ------------------------
# ì¸ë±ìŠ¤ êµ¬ì¶• (ìˆ˜ë™ ë²„íŠ¼)
# ------------------------
if st.button("ğŸ”¨ ì¸ë±ìŠ¤ êµ¬ì¶•"):
    if not uploaded_files:
        st.warning("ë¨¼ì € íŒŒì¼(.txt/.pdf)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        st.session_state.splits = build_splits_from_uploads(uploaded_files, chunk_size, chunk_overlap)
        st.success(f"ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ! ì²­í¬ ìˆ˜: {len(st.session_state.splits)}")

# ------------------------
# ì§ˆë¬¸í•˜ê¸° (ìë™ ì¸ë±ìŠ¤ êµ¬ì¶• ì§€ì› + í•œë„ ì´ˆê³¼ ëŒ€ë¹„)
# ------------------------
st.subheader("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")
q = st.text_input("ì˜ˆ: ì´ ë¬¸ì„œì˜ í•µì‹¬ ìš”ì•½ì€?")
top_k = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ (k)", 1, 10, 4)
ask = st.button("ì§ˆë¬¸ ë³´ë‚´ê¸°")

if ask:
    # 1) ì¸ë±ìŠ¤ ì—†ìœ¼ë©´ ìë™ êµ¬ì¶•
    if not st.session_state.splits and uploaded_files:
        with st.spinner("ì¸ë±ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ êµ¬ì¶•í•˜ëŠ” ì¤‘..."):
            ensure_index_from_uploads()

    # 2) ê¸°ë³¸ ì²´í¬
    if not st.session_state.splits:
        st.warning("ë¨¼ì € íŒŒì¼(.txt/.pdf)ì„ ì—…ë¡œë“œí•˜ê³  ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.")
        st.stop()
    if not q.strip():
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        st.stop()
    if not api_key:
        st.error("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Secretsì— í‚¤ë¥¼ ë“±ë¡í•˜ì„¸ìš”.")
        st.stop()

    # 3) ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    top_docs = rank_by_keywords(q, st.session_state.splits, int(top_k))
    context = "\n\n---\n\n".join([d["text"] for d in top_docs])
    sources = ", ".join(sorted({d["source"] for d in top_docs}))

    # 4) í”„ë¡¬í”„íŠ¸
    template = dedent("""\
    ë‹¹ì‹ ì€ ì—…ë¡œë“œëœ ìë£Œë¥¼ ê·¼ê±°ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
    [ìë£Œ]
    {context}

    [ì§ˆë¬¸]
    {question}

    ê·œì¹™:
    - ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€
    - ë§ˆì§€ë§‰ ì¤„ì— 'ê·¼ê±°:' ë’¤ì— ì¶œì²˜ íŒŒì¼ëª… ë‚˜ì—´

    ë‹µë³€:
    """)
    prompt = PromptTemplate.from_template(template)

    # 5) LLM í˜¸ì¶œ (RateLimit ëŒ€ë¹„: ì»¨í…ìŠ¤íŠ¸ ìë¥´ê¸° + ì¬ì‹œë„)
    MAX_CTX_CHARS = 7000
    ctx = context if len(context) <= MAX_CTX_CHARS else context[:MAX_CTX_CHARS]

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2,
        max_retries=6,   # LangChain ë‚´ì¥ ì§€ìˆ˜í˜• ì¬ì‹œë„
        timeout=60
    )

    def ask_with_backoff(q_text, ctx_text):
        try:
            return llm.invoke(prompt.format(context=ctx_text, question=q_text)).content
        except RateLimitError:
            # 1ì°¨ 429: ì§§ê²Œ ëŒ€ê¸° í›„ ë” ì§§ì€ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„
            short_ctx = ctx_text[:4000]
            time.sleep(2)
            return llm.invoke(prompt.format(context=short_ctx, question=q_text)).content

    try:
        resp = ask_with_backoff(q, ctx)
    except RateLimitError:
        st.error("OpenAI API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ì§ˆë¬¸/ë¬¸ë§¥ ê¸¸ì´ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
        st.stop()
    except Exception as e:
        st.error(f"ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {type(e).__name__}: {e}")
        st.stop()

    # 6) 'ê·¼ê±°:' ë³´ê°• ë° ëŒ€í™” ê¸°ë¡
    if "ê·¼ê±°:" not in resp:
        resp += f"\n\nê·¼ê±°: {sources if sources else 'ì—…ë¡œë“œ ìë£Œ'}"

    st.session_state.history.append(("user", q))
    st.session_state.history.append(("bot", resp, list(sorted({d['source'] for d in top_docs}))))

# ------------------------
# ëŒ€í™” ê¸°ë¡
# ------------------------
st.subheader("ğŸ§¾ ëŒ€í™” ê¸°ë¡")
for item in st.session_state.history:
    if item[0] == "user":
        st.markdown(f'<div class="chat-bubble-user"><b>ë‚˜</b><br>{item[1]}</div>', unsafe_allow_html=True)
    else:
        ans, srcs = item[1], item[2]
        st.markdown(f'<div class="chat-bubble-bot"><b>ë´‡</b><br>{ans}</div>', unsafe_allow_html=True)
        if srcs:
            with st.expander("ğŸ” ì°¸ê³ /ê·¼ê±° ë¬¸ì„œ"):
                for s in srcs:
                    st.markdown(f"- `{s}`")

# ------------------------
# í‘¸í„°
# ------------------------
import time as _t
st.markdown(
    f'<p class="tiny">Â© {_t.strftime("%Y")} ì¤‘ê°„ê³ ì‚¬ìš© RAG ì´ˆì•ˆì •íŒ | Secretsì— OPENAI_API_KEY ë“±ë¡ í•„ìˆ˜.</p>',
    unsafe_allow_html=True
)


